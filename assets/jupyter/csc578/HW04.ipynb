{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 4: Generalizaiton and regularization\n",
        "\n"
      ],
      "metadata": {
        "id": "EW4y2n5GwR9X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0 - Introduction to PyTorch and Autograd"
      ],
      "metadata": {
        "id": "IeUPWMrIwsGw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Week 2, we introduced the concept of a `computational graph`, which is used to efficiently compute gradients in deep neural networks. The key idea is to track intermediate values during forward computation, as these values are used again for backpropagation. By storing these intermediate values, we can significantly reduce the computational cost during gradient computation.\n",
        "\n",
        "This concept of using a computational graph to compute gradients is implemented in PyTorch, originally developed by Facebookâ€™s AI Research (FAIR) group (now part of Meta), through a process called **automatic differentiation**, also known as `autograd`.\n",
        "\n",
        "Similar to `numpy`, in PyTorch, we define variables as **tensors**. PyTorch tensors have an additional feature: if `requires_grad=True`, they automatically track operations for gradient computation."
      ],
      "metadata": {
        "id": "xrrddIe_wsgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "torch.manual_seed(0) # seed for reproducing\n",
        "\n",
        "x = torch.tensor(1.0, requires_grad=True)\n",
        "y = torch.tensor(2.0, requires_grad=True)\n",
        "z = x ** 2 + 2*y ** 2\n",
        "\n",
        "print(f\"x.requires_grad: {x.requires_grad}\")\n",
        "print(f\"y.requires_grad: {y.requires_grad}\")\n",
        "print(f\"z.requires_grad: {z.requires_grad}\")"
      ],
      "metadata": {
        "id": "BTMmGILL1acx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1efb2f34-b34c-4b1d-9e6f-54be46ebfd77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.requires_grad: True\n",
            "y.requires_grad: True\n",
            "z.requires_grad: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example:\n",
        "\n",
        "- `x` and `y` are tensors with `requires_grad=True`, meaning they are being tracked for gradient computation.\n",
        "- The result, `z`, also has `requires_grad=True`, since it's the result of an operation involving tensors that require gradients."
      ],
      "metadata": {
        "id": "Vpr4p2ZwRBYj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define two tensor variables, `x` and `y`, and set `requires_grad=True` to indicate that PyTorch should track their gradients. This means that PyTorch will construct a computational graph involving `x` and `y` whenever operations are performed on them.\n",
        "\n",
        "In this example, we use `x` and `y` to compute `a`. To compute the gradients of `z` with respect to `x` and `y`, we simply call `z.backward()`. This applies the **chain rule**, propagating the gradients backward through the computational graph. The gradients of `z` with respect to `x` and `y` can then be accessed by calling `x.grad` and `y.grad`."
      ],
      "metadata": {
        "id": "SRZnhxbD13VM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z.backward()\n",
        "print(f\"Gradient of x: {x.grad}\")\n",
        "print(f\"Gradient of y: {y.grad}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMkDLHzO2p_I",
        "outputId": "0e49937d-e75f-4def-a524-af9efa3a513b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient of x: 2.0\n",
            "Gradient of y: 8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also visualize the computational graph by inspecting `z.grad_fn`, which shows the function that created `z`. This is useful for understanding how PyTorch constructs the graph and tracks operations. Each operation is represented as a node in the graph, and by calling `grad_fn`, we can see the chain of operations that led to the final result, allowing us to trace the graph backward for gradient computation."
      ],
      "metadata": {
        "id": "J9fmr8J2297v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(1.0, requires_grad=True)\n",
        "y = torch.tensor(2.0, requires_grad=True)\n",
        "z = x ** 2 + 2*y ** 2\n",
        "a = torch.sin(z)\n",
        "\n",
        "print(f\"a.requires_grad: {a.requires_grad}\")\n",
        "print(a.grad_fn)\n",
        "print(a.grad_fn.next_functions)\n",
        "print(z.grad_fn)\n",
        "print(x.grad_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fX3ZDzck29NH",
        "outputId": "06c3e432-d5ca-4282-df25-1f011a45b2d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a.requires_grad: True\n",
            "<SinBackward0 object at 0x7fcd1f42fdc0>\n",
            "((<AddBackward0 object at 0x7fcd1f42e5f0>, 0),)\n",
            "<AddBackward0 object at 0x7fcd1f42fdc0>\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example:\n",
        "- `print(a.grad_fn)`: Shows the function that created `a`, which will be `SinBackward`, indicating a was generated by the `sin` operation.\n",
        "\n",
        "- `print(a.grad_fn.next_functions)`: Displays the previous functions in the graph that led to `a`. This shows the operations applied to `z` before `sin`.\n",
        "\n",
        "- `print(z.grad_fn)`: Prints the function that created `z` (i.e., `AddBackward`), which matches `a.grad_fn.next_functions`.\n",
        "- `print(x.grad_fn)`: This shows `None` because `x` is a leaf tensor, meaning it was not created by any function but was initialized directly. Leaf tensors do not have a `grad_fn`."
      ],
      "metadata": {
        "id": "_TQRua7oSkuW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To stop gradient tracking, we can use `.detach()` to remove a tensor from the computational graph. In this example, we detach the tensor `x`, creating `x_detached`. When we call `a.backward()`, the detached tensor will not have gradients, and its `requires_grad` flag will be set to `False`."
      ],
      "metadata": {
        "id": "jMxd1TZy37Zr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(1.0, requires_grad=True)\n",
        "y = torch.tensor(2.0, requires_grad=True)\n",
        "z = x ** 2 + 2*y ** 2\n",
        "\n",
        "x_detached = x.detach()\n",
        "z.backward()\n",
        "\n",
        "print(f\"x.requires_grad: {x.requires_grad}\")\n",
        "print(f\"x_detached.requires_grad: {x_detached.requires_grad}\")\n",
        "\n",
        "print(f\"x.grad: {x.grad}\")\n",
        "print(f\"x_detached.grad: {x_detached.grad}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FRIC1yO4MBi",
        "outputId": "b7351d4f-c301-4f72-9968-e8a1b4f278f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.requires_grad: True\n",
            "x_detached.requires_grad: False\n",
            "x.grad: 2.0\n",
            "x_detached.grad: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, it's important to note that `x_detached` is not a **deep copy** of `x`. Both tensors share the same memory location, but `x_detached` is excluded from the computational graph used for automatic differentiation. This means if you modify `x_detached` **in-place**, the value of `x` may also change.\n",
        "\n",
        "To avoid this, if you want to modify `x_detached` without affecting the original `x`, you can use `x.clone()` to create an actual copy of the tensor.\n",
        "\n",
        "To reduce this probalic senario, if you want to modify the value of `x_detached` but dont want to effect the value in the original `x`. You can use `x.clone()` to get a copy of `x`."
      ],
      "metadata": {
        "id": "hdbshDxG4t6C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(1.0, requires_grad=True)\n",
        "y = torch.tensor(2.0, requires_grad=True)\n",
        "z = x ** 2 + 2*y ** 2\n",
        "\n",
        "x_clone = x.clone()\n",
        "x_clone = torch.tensor(5.0)\n",
        "print(f\"x_clone: {x_clone}\")\n",
        "print(f\"x: {x}\")\n",
        "\n",
        "print(f\"x_clone.requires_grad: {x_clone.requires_grad}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hko_VGB5nUN",
        "outputId": "f7a2c4d1-e901-4a5c-8ac2-e4c4acad8ac5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_clone: 5.0\n",
            "x: 1.0\n",
            "x_clone.requires_grad: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In PyTorch, when you use the `clone()` method, the cloned tensor retains the same `requires_grad` setting as the original tensor. So if the original tensor `x` has `requires_grad=True`, the cloned tensor `x_clone` will also have `requires_grad=True`. This is why, in your example, `x_clone.requires_grad` is `True`.\n",
        "\n",
        "If you want the cloned tensor to **not track gradients**, you can explicitly set `requires_grad=False` after cloning:"
      ],
      "metadata": {
        "id": "qeWfmm4EW2tm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_clone = x.clone().detach()\n",
        "print(f\"x_clone.requires_grad: {x_clone.requires_grad}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09d6wCUaZK5R",
        "outputId": "7fdb9465-5396-42d5-f9ce-adda61d92a77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_clone.requires_grad: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another way to **temporarily** prevent gradient tracking when you only need to use the current value of `x` for some computation is to use `torch.no_grad()`. This context manager disables gradient tracking for all operations inside its block, making it useful when you want to perform computations without affecting the computational graph."
      ],
      "metadata": {
        "id": "kl6ikGFl-1An"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(1.0, requires_grad=True)\n",
        "y = torch.tensor(2.0, requires_grad=True)\n",
        "z = x ** 2 + 2 * y ** 2\n",
        "\n",
        "with torch.no_grad():\n",
        "    a = torch.sin(x)\n",
        "\n",
        "print(f\"a.requires_grad: {a.requires_grad}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcIwXUpb_TUH",
        "outputId": "63f661c6-208a-4130-910b-f43e1dec4f11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a.requires_grad: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After exiting the `no_grad()` block, a no longer tracks gradients, as confirmed by `a.requires_grad` being `False`. This is useful when you want to do computations that donâ€™t need gradients, such as during the inference phase or when updating non-trainable parameters."
      ],
      "metadata": {
        "id": "Et5ihEGi-1DR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 - Build a Neural Network and Train using `autograd`\n",
        "\n",
        "We have briefly introduced how `autograd` uses computational graphs to efficiently compute gradients. Now, let's use `autograd` to train a deep neural network (DNN)."
      ],
      "metadata": {
        "id": "1ncvZEGPwtIZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 - Define `ShallowNet` [10/10]\n",
        "\n",
        "The first step is to define a two-layer neural network class called `ShallowNet` using `torch.nn`.\n",
        "\n",
        "**Exercise 1 [10/10]**\n",
        "1. The `ShallowNet` takes input size `n_x`, output size `n_y`, and width `n_h`.\n",
        "2. Instead of manually specifying weights and biases, use `nn.Linear()` to define **linear transformations** to compute preactivation that include weights and biases internally.\n",
        "3. Define the activation function `self.act` as a class attribute using `nn.ReLU()`.\n",
        "4. Implement the `forward()` method to perform forward propagation and return the output of the network.\n",
        "\n",
        "**Note** that, thanks to `autograd()`, you don't need to manually implement *backpropagation* as you did before.\n",
        "\n"
      ],
      "metadata": {
        "id": "7bWx7XUPHAaT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class ShallowNet(nn.Module):\n",
        "    def __init__(self, n_x, n_h, n_y):\n",
        "        super(ShallowNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(n_x, n_h)\n",
        "        self.fc2 = nn.Linear(n_h, n_y)\n",
        "        self.act = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass: x -> linear() -> act() -> linear()\n",
        "        ### Code Here ###\n",
        "\n",
        "        ### Code Here ###\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "0EF60xo_Dmz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of how to initialize the network\n",
        "n_x = 4  # Input size\n",
        "n_h = 10  # Hidden layer width\n",
        "n_y = 1  # Output size\n",
        "\n",
        "model = ShallowNet(n_x, n_h, n_y)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPyis7kUa_f7",
        "outputId": "8a5fbd73-5502-4bf5-c2b0-0ef5b8d71b8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ShallowNet(\n",
            "  (fc1): Linear(in_features=4, out_features=10, bias=True)\n",
            "  (fc2): Linear(in_features=10, out_features=1, bias=True)\n",
            "  (act): ReLU()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples = 8\n",
        "x = torch.randn(num_samples, n_x)\n",
        "output = model(x)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gz8BQkeubr71",
        "outputId": "fea44718-5491-412a-b6d3-14635f008afd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.3817],\n",
            "        [ 0.3093],\n",
            "        [ 0.2687],\n",
            "        [ 0.1068],\n",
            "        [-0.0068],\n",
            "        [ 0.0091],\n",
            "        [ 0.1560],\n",
            "        [ 0.1721]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation:\n",
        "- `nn.Linear(n_x, n_h)`: Defines a fully connected layer from input size `n_x` to hidden layer size `n_h`.\n",
        "- `self.act = nn.ReLU()`: Defines the ReLU activation function.\n",
        "- `forward()` method: Implements the forward propagation, applying the activation function after the first layer and passing the result through the second layer to produce the output.\n",
        "\n",
        "You can now use `autograd()` to automatically handle backpropagation during training."
      ],
      "metadata": {
        "id": "NWNLuVTVbFpi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 - Define Loss Function and Optimizer [10/10]\n",
        "\n",
        "To train the `ShallowNet`, we need to specify both a loss function and an optimizer. For example, we can use `nn.MSELoss()` as the loss function, and `torch.optim.SGD()` as the optimizer. The optimizer requires `model.parameters()` and a learning rate, which we define as `learning_rate`."
      ],
      "metadata": {
        "id": "kkqXyIBAcBLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the loss function\n",
        "criterion = nn.MSELoss()  #\n",
        "\n",
        "# Define the optimizer (SGD)\n",
        "learning_rate = 0.01\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "veRjQiHKEAGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's train this simple neural network using *full-batch gradient descent*, where we use all the training data in each step, instead of mini-batches.\n",
        "\n",
        "**Exercise 2 [10/10]:**\n",
        "1. In each training loop, evaluate the `model` on the entire training set `x` to obtain the `output`.\n",
        "2. Compute the `loss` by using the predefined loss function `criterion` and comparing the `output` with the ground truth labels `y`.\n",
        "3. Use autograd to compute the gradients by calling `loss.backward()` instead of calling `model.backward()` like we did in the last assignment\n",
        "4. The computed gradients are automatically stored in the `model`â€™s parameters, which are passed into the `optimizer`. Apply a gradient descent update by calling `optimizer.step()` as done in the previous assignment.\n"
      ],
      "metadata": {
        "id": "9vlZj3hScxOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate random data (full-batch)\n",
        "torch.manual_seed(0) # For reproduce\n",
        "\n",
        "x = torch.randn(num_samples, n_x)\n",
        "y = torch.randn(num_samples, 1)\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad()  # Clear previous gradients\n",
        "\n",
        "    # Forward pass\n",
        "    ### Code Here ###\n",
        "\n",
        "\n",
        "    ### Code Here ###\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    ### Code Here ###\n",
        "\n",
        "\n",
        "    ### Code Here ###\n",
        "\n",
        "    # Print the loss\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVRnJsMEcwp_",
        "outputId": "593d5527-1b6d-4af4-eeb2-ba4fd32c69bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.9464\n",
            "Epoch [2/10], Loss: 0.9357\n",
            "Epoch [3/10], Loss: 0.9255\n",
            "Epoch [4/10], Loss: 0.9158\n",
            "Epoch [5/10], Loss: 0.9066\n",
            "Epoch [6/10], Loss: 0.8978\n",
            "Epoch [7/10], Loss: 0.8893\n",
            "Epoch [8/10], Loss: 0.8812\n",
            "Epoch [9/10], Loss: 0.8734\n",
            "Epoch [10/10], Loss: 0.8660\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**:\n",
        "- In PyTorch, when using `torch.optim.SGD()`, gradient descent (GD) is automatically implemented if you pass the entire dataset as a single batch (like in the example above).\n",
        "- If you do not specify a batch size while loading data (e.g., using `DataLoader`), it defaults to using the full dataset, performing full-batch gradient descent.\n",
        "- To use mini-batch stochastic gradient descent (SGD), you need to load your data in mini-batches using a DataLoader with a specified batch_size."
      ],
      "metadata": {
        "id": "TsrSy1ikejmT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 - Use `DataLoader` for Mini-Batch SGD [20/20]\n",
        "\n",
        "In this exercise, we will modify the training loop to use mini-batch stochastic gradient descent (SGD) by loading the data in mini-batches using PyTorch's `DataLoader`.\n",
        "\n",
        "**Exercise 3 [10/10]**:\n",
        "1. Generate random data `x` and `y` as before.\n",
        "2. In PyTorch, use `TensorDataset(x, y)` to wrap the input tensor `x` and label tensor `y` into a dataset. Ensure that the first dimension (number of samples) matches for both tensors.\n",
        "3. PyTorchâ€™s `DataLoader` can automatically divide a dataset into mini-batches and shuffle the data after each epoch when `shuffle=True` is set.\n",
        "4. Set the `batch_size=64` and shuffle=True when creating the data_loader.\n"
      ],
      "metadata": {
        "id": "D3TlzM07e8Fs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Generate random data (as tensors)\n",
        "num_samples = 1000\n",
        "n_x = 10  # Number of features\n",
        "n_y = 1  # Number of output features\n",
        "x = torch.randn(num_samples, n_x)  # Input data\n",
        "y = torch.randn(num_samples, 1)    # Target output\n",
        "\n",
        "# Create a TensorDataset and DataLoader for mini-batch processing\n",
        "dataset = TensorDataset(x, y)\n",
        "batch_size = 32\n",
        "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "W6LXyfUdEGQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 4 [10/10]:** Now that we have the mini-batches prepared, we can use SGD with mini-batches to train the `ShallowNet`.\n",
        "\n",
        "1. Define a `ShallowNet` with a hidden layer width `n_h=10`.\n",
        "2. Specifiy the loss `criterion` using `MSELoss()`\n",
        "3. Define the SGD `optimizer` using `torch.optim.SGD`\n",
        "4. For each mini-batch, `data_loader` return a `(inputs, targets)` pair.\n",
        " - We evaluate our `model` on the `inputs` to get `outputs`\n",
        " - Then compute the `loss` using `outputs` and `targets`\n",
        " - Compute the gradients by calling `loss.backward()`\n",
        " - Employ the gradient update using `optimizer.step()`"
      ],
      "metadata": {
        "id": "XfIGX7kWEKCR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.random.manual_seed(0) # For reproduce\n",
        "# Define the model, loss function, and optimizer\n",
        "n_h = 10  # Hidden layer width\n",
        "model = ShallowNet(n_x=n_x, n_h=n_h, n_y=n_y)\n",
        "criterion = torch.nn.MSELoss()\n",
        "learning_rate = 0.01\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop with mini-batch SGD\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "\n",
        "    # Loop over mini-batches\n",
        "    ### Code Here ###\n",
        "    for\n",
        "    ### Code Here ###\n",
        "        optimizer.zero_grad()  # Clear previous gradients\n",
        "\n",
        "        # Forward pass: compute the model's output for the mini-batch\n",
        "        ### Code Here ###\n",
        "\n",
        "        ### Code Here ###\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        ### Code Here ###\n",
        "\n",
        "\n",
        "        ### Code Here ###\n",
        "\n",
        "        # Accumulate loss for printing\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Print the average loss for the current epoch\n",
        "    avg_loss = running_loss / len(data_loader)\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MzDRh1wcwsh",
        "outputId": "331372df-4a21-46a6-92cc-b039c8f9f77d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 1.1037\n",
            "Epoch [2/10], Loss: 1.0542\n",
            "Epoch [3/10], Loss: 1.0580\n",
            "Epoch [4/10], Loss: 1.0350\n",
            "Epoch [5/10], Loss: 1.0737\n",
            "Epoch [6/10], Loss: 1.0209\n",
            "Epoch [7/10], Loss: 1.0275\n",
            "Epoch [8/10], Loss: 1.0241\n",
            "Epoch [9/10], Loss: 1.0418\n",
            "Epoch [10/10], Loss: 1.0044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**:\n",
        "- `running_loss` is used to keep track of the total loss across all mini-batches within each epoch.\n",
        "- `avg_loss` computes the average loss over the entire epoch\n",
        "- `optimizer.zero_grad()` clears the previously computed gradients as, in PyTorch, gradients are accumulated over mini-batches by default.\n",
        "- `len(data_loader)` gives the number of *mini-batches* in the dataset: `num_samples` divided by `batch_size`. In our case, $\\lceil 1000/32\\rceil  = 32$\n",
        "- The total number of *training iterations (loops)* is calculated by multiplying the `num_epochs` by the number of mini-batches per epoch. In our example, we have $10 \\times 32 = 320$ training loops"
      ],
      "metadata": {
        "id": "LbS9s0_ihu6Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4 - Train on a realistic dataset using Pytorch [40/40]"
      ],
      "metadata": {
        "id": "lK1mFPPjGTyt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let us load the MNIST data set. This time we will use `torch`."
      ],
      "metadata": {
        "id": "1Ybv3FiqHfSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=torchvision.transforms.ToTensor())\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=torchvision.transforms.ToTensor())\n",
        "\n",
        "print(f\"Number of training samples: {len(train_dataset)}\")\n",
        "print(f\"Number of test samples: {len(test_dataset)}\")\n",
        "print(f\"Input shape: {train_dataset[0][0].shape}\")"
      ],
      "metadata": {
        "id": "YMuyaJfNI_Sx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bc7548a-d91f-4c67-8e8b-5ef15d0016ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 111] Connection refused>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9.91M/9.91M [00:02<00:00, 4.12MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 111] Connection refused>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28.9k/28.9k [00:00<00:00, 132kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 111] Connection refused>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.65M/1.65M [00:01<00:00, 1.26MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 111] Connection refused>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.54k/4.54k [00:00<00:00, 4.22MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Number of training samples: 60000\n",
            "Number of test samples: 10000\n",
            "Input shape: torch.Size([1, 28, 28])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is generally recommended to get familiar or get a sense of the dataset before working on the machine learning task. As MNIST is an image dataset, it would be nice just print the image and take a look using the following function."
      ],
      "metadata": {
        "id": "HYS5Roe_Mrh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_images(dataset, num_images=5):\n",
        "    random_indices = torch.randperm(len(dataset))[:num_images]  # Randomly shuffle indices and pick num_images\n",
        "    fig, axes = plt.subplots(1, num_images, figsize=(12, 4))\n",
        "\n",
        "    for i, idx in enumerate(random_indices):\n",
        "        # Get image and label\n",
        "        image, label = dataset[idx]\n",
        "        if image.ndim == 3:  # Check if the image has 3 channels (RGB)\n",
        "            image = image.permute(1, 2, 0)  # Rearrange dimensions to (Height, Width, Channels)\n",
        "        else:\n",
        "            image = image.squeeze()  # Remove the channel dimension for plotting (1x28x28 -> 28x28)\n",
        "\n",
        "        # Plot the image\n",
        "        axes[i].imshow(image, cmap='gray')\n",
        "        axes[i].set_title(f\"Label: {label}\")\n",
        "        axes[i].axis('off')  # Turn off the axis\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "eGRaJ6_vM9jV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the random 5 images from `train_data_full`\n",
        "plot_images(train_dataset, num_images=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "Fw5gCL5-NF_E",
        "outputId": "4b2d1549-54d8-4f35-cc17-630c73ed263a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 5 [10/10]**: To apply SGD with mini-batch, we need `DataLoader` to load the data as mini-batches. Additionally, to moniter the performance not only during the training but also the test dataset (or validation dataset for tuning), we need both `train_loader` and `test_loader`.\n",
        "1. Define `batch_size` with size value `64`\n",
        "2. Define `train_loader` using `DataLoader`, ensuring the `shuffle=True` flag is set to randomly shuffle the training data after each epoch.\n",
        "3. Define `test_loader` using `DataLoader` for the test dataset, and since itâ€™s not necessary to shuffle the test data, you can leave the shuffle flag as the default (False).\n"
      ],
      "metadata": {
        "id": "LbKdy9uONFmQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoaders\n",
        "### Code Here ###\n",
        "\n",
        "### Code Here ###\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "aTiTKLTvHGgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have the training and test datasets ready in **mini-batch form**, we can define our `model`, loss `criterion`, and `optimizer` to start training.\n",
        "\n",
        "**Exercise 6 [10/10]:**\n",
        "1. Use `ShallowNet` to define a two-layer network `model` with `10` hidden units and `n_y=10` as MNIST contains `10` digits.\n",
        "2. Specify the loss critarion to be `nn.MSELoss()`\n",
        "3. Define SGD optimizer using `torch.optim.SGD()` by passing the learning rate and the model's parameters\n",
        "4. For each epoch, we loop over each mini-batch `(inputs, targets)` loaded from `train_loader`:\n",
        "  - Since each image in `inputs` has shape `28x28`, but the MLP treats input as a **vector**, reshape inputs using `.view(-1)` to flatten the images.\n",
        "  - Compute the `outputs` by passing the `inputs` through the `model`\n",
        "  - The model is designed for `10` output classes, but targets are integer values (class labels). Convert targets to **One-Hot Encoding** using `torch.nn.functional.one_hot(targets, num_classes=10)`.\n",
        "  - Compute the `train_loss` using `critarion` on `outputs` and `targets`\n",
        "  - Accumulate the `train_loss` into `train_running_loss`\n",
        "  - Perform gradient computation and take the optimization step to update model's parameters.\n",
        "  - Apply the same steps to `test_loader` to compute `test_loss` and update `test_running_loss`, excpet for skipping gradient computaiton and optimization steps\n",
        "\n",
        "5. At end of each epoch, store the averaged `train_running_loss` and `test_running_loss` into `train_losses` and `test_losses`, respecitvely.\n",
        "\n"
      ],
      "metadata": {
        "id": "rq-vleGnQ1Xv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.functional import one_hot\n",
        "\n",
        "torch.manual_seed(0) # For reproduce\n",
        "\n",
        "n_y = 10 # 10 classes\n",
        "model = ShallowNet(n_x=28*28, n_h=10, n_y=n_y)\n",
        "criterion = nn.MSELoss()\n",
        "learning_rate = 0.01\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    train_running_loss = 0.0\n",
        "    test_running_loss = 0.0\n",
        "\n",
        "    # Test loop\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in test_loader:\n",
        "            ### Code Here ###\n",
        "\n",
        "\n",
        "            ### Code Here ###\n",
        "            outputs = model(inputs)\n",
        "            test_loss = criterion(outputs, targets)\n",
        "            test_running_loss += test_loss.item()\n",
        "\n",
        "    # Training loop\n",
        "    model.train()  # Set the model to training mode\n",
        "    for i, (inputs, targets) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()  # Clear previous gradients\n",
        "        ### Code Here ###\n",
        "\n",
        "\n",
        "        ### Code Here ###\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        train_loss = criterion(outputs, targets)\n",
        "        train_running_loss += train_loss.item()\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    train_losses.append(train_running_loss / len(train_loader))\n",
        "    test_losses.append(test_running_loss / len(test_loader))\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_losses[-1]:.4f}, Test Loss: {test_losses[-1]:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxk8FAjBUB9Y",
        "outputId": "88acc842-19ad-4a45-edb0-e7af319bb778"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Train Loss: 0.0874, Test Loss: 0.1305\n",
            "Epoch [2/10], Train Loss: 0.0730, Test Loss: 0.0769\n",
            "Epoch [3/10], Train Loss: 0.0661, Test Loss: 0.0688\n",
            "Epoch [4/10], Train Loss: 0.0612, Test Loss: 0.0629\n",
            "Epoch [5/10], Train Loss: 0.0575, Test Loss: 0.0587\n",
            "Epoch [6/10], Train Loss: 0.0546, Test Loss: 0.0554\n",
            "Epoch [7/10], Train Loss: 0.0525, Test Loss: 0.0529\n",
            "Epoch [8/10], Train Loss: 0.0508, Test Loss: 0.0510\n",
            "Epoch [9/10], Train Loss: 0.0495, Test Loss: 0.0495\n",
            "Epoch [10/10], Train Loss: 0.0485, Test Loss: 0.0484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have obtained `train_losses` and `test_losses`, it is essential to check the convergence behavior to determine whether it is smooth without significant damping or oscillation. If oscillations occur, we may need to consider shrinking the learning rate. In this exercise, you will implement a function `plot_losses()` to visualize the losses on the same plot.\n",
        "\n",
        "**Exercise 7 [10/10]:**\n",
        "1. We need to import `matplotlib.pyplot` as `plt` as for ploting\n",
        "2. The function `plot_losses` takes `train_losses` and `test_losses` as input\n",
        "3. Use `plt.figure()` to define a figure with specified `figsize=(10,6)`\n",
        "4. Plot train_losses using `plt.plot()`. To distinguish it from `test_losses`, specify parameters such as `label`, `color`, and `linestyle`.\n",
        "5. Plot `test_losses` as the `train_losses`\n",
        "6. Add labels and title\n",
        "7. Add legend\n",
        "8. Finish ploting, we `plt.show()` the plotted figure.\n"
      ],
      "metadata": {
        "id": "6c1tXBWjR8H_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_losses(train_losses, test_losses):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # Plot training losses (blue dashed line)\n",
        "    plt.plot(train_losses, label='Training Loss', color='blue', linestyle='--')\n",
        "\n",
        "    # Plot test losses (red solid line)\n",
        "    ### Code Here ###\n",
        "\n",
        "\n",
        "    ### Code Here ###\n",
        "\n",
        "    # Add labels and title\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Test Loss Over Epochs')\n",
        "\n",
        "    # Add a legend\n",
        "    plt.legend()\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "79NNzh98dYS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the train and test losses\n",
        "plot_losses(train_losses, test_losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "-GAurU8udZGA",
        "outputId": "d2176e0f-241f-43cf-e84e-2627ab6e6218"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the model is trained, we can use it to make predictions and calculate the accuracy.\n",
        "\n",
        "**Exercise 8 [10/10]**:\n",
        "1. The `predict_and_accuracy` takes a `model` and `data_loader`\n",
        "2. Loop over the `data_loader`, similar to how you handled the test loop:\n",
        " - For each mini-batch, compute the `outputs` by applying the `model` on `inputs`.\n",
        " - Use `torch.max(outputs.data, 1)` to retrieve the `predicted` class labels by finding the index of the maximum logit value in `outputs`.\n",
        " - We collect the `predicted` labels into the previous collection `predicitons` using `extend()` as to append a `list` to another `list` in Python\n",
        " - UUpdate the total number of predictions made (`total`) and the total number of correct predictions (`correct`).\n",
        "3. After completing the loop, compute the `accuracy` as the ratio of correct predictions to the total number of predictions (`correct / total`).\n",
        "4. Return total `predicitons` and `accuracy`"
      ],
      "metadata": {
        "id": "ZSG4gAk3vyQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_and_accuracy(model, data_loader):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    predictions = []\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation during prediction\n",
        "        for inputs, targets in data_loader:\n",
        "            inputs = inputs.view(-1, 28 * 28)  # Flatten the images\n",
        "            outputs = model(inputs)\n",
        "            ### Code Here ###\n",
        "\n",
        "\n",
        "            ### Code Here ###\n",
        "            predictions.extend(predicted.tolist())\n",
        "            total += targets.size(0)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "\n",
        "    ### Code Here ###\n",
        "\n",
        "\n",
        "    ### Code Here ###\n",
        "    return predictions, accuracy\n"
      ],
      "metadata": {
        "id": "77b4a-ZZvJyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Accuracy:\n",
        "predictions, accuracy = predict_and_accuracy(model, train_loader)\n",
        "print(f\"Training Accuracy:: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4Dz3aXss-fq",
        "outputId": "7ce5a657-399d-4111-c974-b32b5e42ed44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy:: 0.8137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Accuracy\n",
        "predictions, accuracy = predict_and_accuracy(model, test_loader)\n",
        "print(f\"Testing Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1CNehuqsUYu",
        "outputId": "caf1be29-2dd1-4061-cca9-d8607c62c47d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Accuracy: 0.8259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 - Tuning Hyperparameters"
      ],
      "metadata": {
        "id": "eMjp0XqxaFmy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As introduced in the lectures, training deep neural networks (DNNs) involves a variety of choices for hyperparameters, such as:\n",
        "- chocie of loss funcitons,\n",
        "- activaiton funcitons,\n",
        "- leanring rate,\n",
        "- optimizers,\n",
        "- network achetecrures,\n",
        "- etc\n",
        "\n",
        "In this seciton, we will review the tunning strategies introduced in lectures.\n",
        "\n"
      ],
      "metadata": {
        "id": "X8TRVqIbUrXz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 - Train with Cross Entropy Loss [10/10]"
      ],
      "metadata": {
        "id": "9DQAq3jbX75j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Letâ€™s first explore the effect of changing the loss function from mean square error to **cross-entropy loss**. Specifically, we want to check if switching the loss function results in significant differences in training performance.\n",
        "\n",
        "**Note**: When we define `ShallowNet`, the model outputs raw real values (*logits*). However, when using cross-entropy loss, the loss function expects the input to represent probabilities, where each value is in $[0,1]$ and the sum is euqal to $1$. This is achieved by applying the **softmax** activation function:\n",
        "$$\n",
        "b_i = \\frac{\\exp(a_i)}{\\sum_{j=1}^{n} \\exp(a_i)}\n",
        "$$\n",
        "However, do not apply softmax **manually** in the `ShallowNet` definition, because `nn.CrossEntropyLoss()` automatically applies softmax internally. Applying softmax twice would result in incorrect behavior and training."
      ],
      "metadata": {
        "id": "NTR50l-GaXIF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 9 [10/10]**:\n",
        "1. Define `model` as `ShallowNet` with `10` hidden units.\n",
        "2. Specify the loss `criterion` as `nn.CrossEntropyLoss()`.\n",
        "3. Set the `optimizer` to SGD (with mini-batches), using a learning rate of `0.01`.\n",
        "4. Train the `mode`l for `10` epochs, recording the `train_losses` and `test_losses` at each epoch.\n",
        "5. Plot the `train_losses` and `test_losses` to visualize the convergence behavior.\n",
        "6. Make predictions on both the training and test datasets, and return their respective `accuracy`."
      ],
      "metadata": {
        "id": "wiNA_w0OVUfJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0) # For reproduce\n",
        "\n",
        "model = ShallowNet(n_x=28*28, n_h=8, n_y=n_y)\n",
        "### Code Here ### (Define loss criterion)\n",
        "\n",
        "\n",
        "### Code Here ###\n",
        "learning_rate = 0.01\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    train_running_loss = 0.0\n",
        "    test_running_loss = 0.0\n",
        "    # Test loop\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in test_loader:\n",
        "            ### Code Here ###\n",
        "\n",
        "\n",
        "            ### Code Here ###\n",
        "            test_running_loss += test_loss.item()\n",
        "\n",
        "    # Training loop\n",
        "    model.train()\n",
        "    for inputs, targets in train_loader:\n",
        "        optimizer.zero_grad()  # Clear previous gradients\n",
        "        ### Code Here ###\n",
        "\n",
        "        ### Code Here ###\n",
        "\n",
        "    train_losses.append(train_running_loss / len(train_loader))\n",
        "    test_losses.append(test_running_loss / len(test_loader))\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_losses[-1]:.4f}, Test Loss: {test_losses[-1]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDP73yxTJVQ7",
        "outputId": "a7d603f9-7f04-44a2-a1d2-4905d6af16a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Train Loss: 1.3421, Test Loss: 2.3165\n",
            "Epoch [2/10], Train Loss: 0.5694, Test Loss: 0.6852\n",
            "Epoch [3/10], Train Loss: 0.4494, Test Loss: 0.4663\n",
            "Epoch [4/10], Train Loss: 0.4003, Test Loss: 0.4021\n",
            "Epoch [5/10], Train Loss: 0.3716, Test Loss: 0.3670\n",
            "Epoch [6/10], Train Loss: 0.3530, Test Loss: 0.3458\n",
            "Epoch [7/10], Train Loss: 0.3402, Test Loss: 0.3344\n",
            "Epoch [8/10], Train Loss: 0.3308, Test Loss: 0.3231\n",
            "Epoch [9/10], Train Loss: 0.3237, Test Loss: 0.3176\n",
            "Epoch [10/10], Train Loss: 0.3177, Test Loss: 0.3128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the train and test losses\n",
        "### Code Here ###\n",
        "plot_losses(train_losses, test_losses)\n",
        "### Code Here ###"
      ],
      "metadata": {
        "id": "k8CzczUXXc54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "3b16ff3d-9dd3-4212-ef72-861da26b6982"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Code Here ###\n",
        "_, train_accuracy = predict_and_accuracy(model, train_loader)\n",
        "_, test_accuracy = predict_and_accuracy(model, test_loader)\n",
        "### Code Here ###\n",
        "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "print(f\"Testing Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PS6-MSbLXGB7",
        "outputId": "edb7201d-9b78-4c33-c3e0-389e95e12647"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 0.9115\n",
            "Testing Accuracy: 0.9132\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, using `CrossEntropyLoss()` results in beter `train_losses` and `test_losses` compared to using `MSELoss()`, but the `accuracy` is much better. Hence, the chocie of hyperparameters influence the performance of DNNs."
      ],
      "metadata": {
        "id": "WGH-AWhUXZJm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 - Tune network width and learning rate [10/10]\n",
        "\n",
        "We will use **random search** to tune two hyperparameters: the **width** (number of hidden units) and the **learning rate**.\n",
        "\n",
        "The possible combinations of learning rate and network width can be represented in a grid as follows:\n",
        "\n",
        "| Learning Rate \\ Width | 2    | 16   | 128  | 1024 |\n",
        "|-----------------------|------|------|------|------|\n",
        "| 1                     |val.  |val.  |val.  |val.  |\n",
        "| 0.1                   |val.  |val.  |val.  |val.  |\n",
        "| 0.01                  |val.  |val.  |val.  |val.  |\n",
        "| 0.001                 |val.  |val.  |val.  |val.  |\n",
        "\n",
        "**Note**: both learning rate and width are in **log scale**.\n",
        "\n"
      ],
      "metadata": {
        "id": "AJwty2cYYF-r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 10 [10/10]**:\n",
        "The first step is to split the `train_dataset` into `train_data` and `val_data`. Since the MNIST dataset is relatively straightforward, the results are not very sensitive to the choice of hyperparameters. Therefore, we can use a `90/10` split ratio by applying the `random_split(data, [size1, size2])` function.\n",
        "\n",
        "Next, to simplify the coding process, we will write the training loop as a function `train_model()` that takes `model`, `train_loader`, loss `criterion`, `optimizer` and `num_epoches` as input.\n",
        "\n",
        "In the third step, we need to define the search space. Create a range of values for both the learning rate and network width, ensuring that both are sampled using **log-scale**. Next, randomly sample `4` learning rates and widths from the defined search space to evaluate different combinations.\n",
        "\n",
        "For each randomly selected combination of learning rate and width, train the model on the training set and validate it on the validation set. Track the performance (e.g., validation accuracy) for comparison.\n",
        "\n"
      ],
      "metadata": {
        "id": "AMPcSbXzequ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split\n",
        "train_size = int(0.9 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "\n",
        "### Code Here ### (random_split train_dataset into train_data and val_data)\n",
        "\n",
        "\n",
        "### Code Here ###\n",
        "print(f\"Number of training samples: {len(train_data)}\")\n",
        "print(f\"Number of validation samples: {len(val_data)}\")\n",
        "\n",
        "# Redefine valudation set loader\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EMEhxp8XNku",
        "outputId": "2082ae0b-7c16-4066-b0d9-cdc09abe5ce7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples: 54000\n",
            "Number of validation samples: 6000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, targets in train_loader:\n",
        "            ### Code Here ###\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            ### Code Here ###\n",
        "\n",
        "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Train Loss: {running_loss / len(train_loader):.4f}\")"
      ],
      "metadata": {
        "id": "4DRi2ZnafWKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rates = torch.logspace(-3, 0, 5)\n",
        "widths = [2, 16, 128, 1024]\n",
        "print(f\"Learning Rate: {learning_rates}\")\n",
        "print(f\"Width: {widths}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5B8KsXFigFBi",
        "outputId": "75929619-a971-4e59-e543-c2514de4127b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning Rate: tensor([0.0010, 0.0056, 0.0316, 0.1778, 1.0000])\n",
            "Width: [2, 16, 128, 1024]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.seed(4) # For reproducibility\n",
        "# Sample random combinations of learning rates and widths\n",
        "random_combinations = [(random.choice(learning_rates), random.choice(widths)) for _ in range(4)]  # Example with 20 combinations\n",
        "print(f\"Random Combinations: {random_combinations}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQFVxhMrhGo5",
        "outputId": "afbf383e-c951-49fb-bf10-dad7bfd382d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Combinations: [(tensor(0.0056), 128), (tensor(0.0010), 1024), (tensor(0.1778), 16), (tensor(0.0010), 2)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = None\n",
        "best_val_accuracy = 0.0\n",
        "\n",
        "for lr, width in random_combinations:\n",
        "    print(f\"Training with Learning Rate = {lr:.6f}, Width = {width}\")\n",
        "\n",
        "    torch.manual_seed(0)  # For reproducibility\n",
        "    # Build and initialize the model with the given width\n",
        "    model = ShallowNet(n_x=28*28, n_h=width, n_y=n_y)\n",
        "\n",
        "    # Define the optimizer with the sampled learning rate\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "    # Define loss criterion\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Train the model on the training set\n",
        "    ### Code Here ###\n",
        "\n",
        "\n",
        "    ### Code Here ###\n",
        "\n",
        "    # Validate the model on the validation set\n",
        "    ### Code Here ###\n",
        "\n",
        "\n",
        "    ### Code Here ###\n",
        "\n",
        "    # Track the best-performing combination\n",
        "    ### Code Here ###\n",
        "    if\n",
        "    ### Code Here ###\n",
        "        best_val_accuracy = val_accuracy\n",
        "        best_params = (lr, width)\n",
        "\n",
        "print(f\"Best parameters found: Learning Rate = {best_params[0]}, Width = {best_params[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfkPb9uIfOpq",
        "outputId": "92a9ab3b-da2b-4e1c-f0c8-935601ef1613"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with Learning Rate = 0.005623, Width = 128\n",
            "Epoch [1/10], Loss: 1.6581\n",
            "Epoch [2/10], Loss: 0.7577\n",
            "Epoch [3/10], Loss: 0.5312\n",
            "Epoch [4/10], Loss: 0.4482\n",
            "Epoch [5/10], Loss: 0.4049\n",
            "Epoch [6/10], Loss: 0.3779\n",
            "Epoch [7/10], Loss: 0.3588\n",
            "Epoch [8/10], Loss: 0.3442\n",
            "Epoch [9/10], Loss: 0.3323\n",
            "Epoch [10/10], Loss: 0.3223\n",
            "Training with Learning Rate = 0.001000, Width = 1024\n",
            "Epoch [1/10], Loss: 2.1743\n",
            "Epoch [2/10], Loss: 1.8915\n",
            "Epoch [3/10], Loss: 1.5737\n",
            "Epoch [4/10], Loss: 1.2786\n",
            "Epoch [5/10], Loss: 1.0545\n",
            "Epoch [6/10], Loss: 0.8986\n",
            "Epoch [7/10], Loss: 0.7903\n",
            "Epoch [8/10], Loss: 0.7127\n",
            "Epoch [9/10], Loss: 0.6548\n",
            "Epoch [10/10], Loss: 0.6100\n",
            "Training with Learning Rate = 0.177828, Width = 16\n",
            "Epoch [1/10], Loss: 0.4211\n",
            "Epoch [2/10], Loss: 0.2501\n",
            "Epoch [3/10], Loss: 0.2155\n",
            "Epoch [4/10], Loss: 0.1946\n",
            "Epoch [5/10], Loss: 0.1815\n",
            "Epoch [6/10], Loss: 0.1732\n",
            "Epoch [7/10], Loss: 0.1668\n",
            "Epoch [8/10], Loss: 0.1619\n",
            "Epoch [9/10], Loss: 0.1551\n",
            "Epoch [10/10], Loss: 0.1495\n",
            "Training with Learning Rate = 0.001000, Width = 2\n",
            "Epoch [1/10], Loss: 2.2896\n",
            "Epoch [2/10], Loss: 2.1741\n",
            "Epoch [3/10], Loss: 2.0789\n",
            "Epoch [4/10], Loss: 1.9932\n",
            "Epoch [5/10], Loss: 1.9205\n",
            "Epoch [6/10], Loss: 1.8617\n",
            "Epoch [7/10], Loss: 1.8131\n",
            "Epoch [8/10], Loss: 1.7711\n",
            "Epoch [9/10], Loss: 1.7336\n",
            "Epoch [10/10], Loss: 1.6996\n",
            "Best parameters found: Learning Rate = 0.17782793939113617, Width = 16\n",
            "Epoch [1/10], Loss: 0.4183\n",
            "Epoch [2/10], Loss: 0.2366\n",
            "Epoch [3/10], Loss: 0.2000\n",
            "Epoch [4/10], Loss: 0.1784\n",
            "Epoch [5/10], Loss: 0.1650\n",
            "Epoch [6/10], Loss: 0.1533\n",
            "Epoch [7/10], Loss: 0.1476\n",
            "Epoch [8/10], Loss: 0.1402\n",
            "Epoch [9/10], Loss: 0.1340\n",
            "Epoch [10/10], Loss: 0.1309\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train with the best parameters\n",
        "torch.manual_seed(0)\n",
        "model = ShallowNet(n_x=28*28, n_h=best_params[1], n_y=n_y)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=best_params[0])\n",
        "train_model(model, train_loader, criterion, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYwlWuqiAdTj",
        "outputId": "6c6c7db3-cdac-40a1-ac56-fc0e8d8eff34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.4211\n",
            "Epoch [2/10], Loss: 0.2501\n",
            "Epoch [3/10], Loss: 0.2155\n",
            "Epoch [4/10], Loss: 0.1946\n",
            "Epoch [5/10], Loss: 0.1815\n",
            "Epoch [6/10], Loss: 0.1732\n",
            "Epoch [7/10], Loss: 0.1668\n",
            "Epoch [8/10], Loss: 0.1619\n",
            "Epoch [9/10], Loss: 0.1551\n",
            "Epoch [10/10], Loss: 0.1495\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, train_accuracy = predict_and_accuracy(model,train_loader)\n",
        "_, val_accuracy = predict_and_accuracy(model,val_loader)\n",
        "_, test_accuracy = predict_and_accuracy(model,test_loader)\n",
        "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
        "print(f\"Testing Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_jIgMi5iTsT",
        "outputId": "fc52b4b3-a5e8-4f01-d25c-6cc567d37a0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 0.9624\n",
            "Validation Accuracy: 0.9495\n",
            "Testing Accuracy: 0.9538\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3- Overparameterizaiton\n",
        "\n",
        "In the lectures, we introduced the concept of overparameterization, where models are built with many more parameters or hidden units than necessary. Here, we define a shallow network with a large number of hidden units, specifically 2048, and use a high learning rate of 1.\n",
        "\n",
        "Because we use a much larger width, the model complexity increases, leading to lower bias and potentially good performance on the training set. However, due to high variance, this may not translate to the test set.\n",
        "\n",
        "Interestingly, the following experiments will demonstrate that an overparameterized model not only struggles to achieve good performance on the training set but can also generalize to the test set. Additionally, the model can be successfully trained even with a large learning rate."
      ],
      "metadata": {
        "id": "NHWWg9Q_rNAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0) # for reproduct\n",
        "width = 2048 # large width\n",
        "model = ShallowNet(n_x=28*28, n_h=width, n_y=10)\n",
        "learning_rate = 1.0\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "print(f\"Training with Learning Rate = {learning_rate}, Width = {width}\")\n",
        "train_model(model, train_loader, criterion, optimizer, num_epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ici2d5fnnPxG",
        "outputId": "33033ef3-7721-442f-83d0-8ef0da1daa88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with Learning Rate = 1.0, Width = 2048\n",
            "Epoch [1/10], Loss: 0.2541\n",
            "Epoch [2/10], Loss: 0.0846\n",
            "Epoch [3/10], Loss: 0.0558\n",
            "Epoch [4/10], Loss: 0.0360\n",
            "Epoch [5/10], Loss: 0.0240\n",
            "Epoch [6/10], Loss: 0.0158\n",
            "Epoch [7/10], Loss: 0.0094\n",
            "Epoch [8/10], Loss: 0.0066\n",
            "Epoch [9/10], Loss: 0.0038\n",
            "Epoch [10/10], Loss: 0.0015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, train_accuracy = predict_and_accuracy(model,train_loader)\n",
        "_, val_accuracy = predict_and_accuracy(model,val_loader)\n",
        "_, test_accuracy = predict_and_accuracy(model,test_loader)\n",
        "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
        "print(f\"Testing Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KH-e9Q3ur2RC",
        "outputId": "a40fa675-3a79-4e1d-f875-f6846a1a6bc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 1.0000\n",
            "Validation Accuracy: 0.9852\n",
            "Testing Accuracy: 0.9846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JOHrFm-n8vna"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}