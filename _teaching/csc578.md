---
layout: course
course_code: CSC578
title: Neural Networks and Deep Learning
semester: Spring 2025, Winter 2025, Fall 2024
instructor: Tianxiang Gao
instructor_url: https://gaotx-cs.github.io/
time: Thursdays 5:45PM - 9:00PM
location: CDM Center 224 at Loop Campus
office_hours: Mondays 9:00AM-11:00AM
zoom: https://depaul.zoom.us/my/gaotx
description: >
  This course covers the foundations of deep learning, including fundamental neural network architectures (e.g., multilayer perceptrons) and training methodologies, including advanced optimization techniques (e.g., momentum, RMSprop, Adam). It also addresses generalization and regularization strategies (e.g., overparameterization, the double descent phenomenon, and weight decay). We will explore cutting-edge neural network architectures, including convolutional neural networks (CNNs), recurrent neural networks (RNNs), transformers (e.g., GPT and BERT), and graph neural networks (GNNs). Students will gain hands-on experience by implementing these models and applying them to real-world problems in computer vision, natural language processing, and graph machine learning.

syllabus: /assets/pdf/teaching/csc578/csc578_syallubs.pdf
ta: Mohammed Azeezulla 
ta_email: mmoha134@depaul.edu
logistics: /assets/pdf/teaching/csc578/00_logistics.pdf
# materials:
#   - title: Lecture on Deep Learning
#     type: slides
#     url: /assets/pdf/teaching/01_intro.pdf
#   - title: Code for Deep Learning
#     type: code
#     url: /assets/pdf/teaching/01_intro.pdf.zip
---


## Prerequisites
- [CSC 412](https://www.cdm.depaul.edu/academics/pages/courseinfo.aspx?Subject=CSC&CatalogNbr=412) provides basic knowledge in linear algebra, multivariate calculus, and probability.
- [DSC 478](https://www.cdm.depaul.edu/academics/pages/courseinfo.aspx?CrseId=012551) or [CSC 480](https://www.cdm.depaul.edu/academics/pages/courseinfo.aspx?CrseId=001513) introduces the fundamental concepts of artificial intelligence and machine learning.
- You will implement and train deep neural networks using PyTorch, so basic Python proficiency is required.

---
## Textbook
No textbook is required. Materials will be drawn from classical books and recent papers. Recommended readings:  

- [Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/) by Michael Nielsen  
- [Deep Learning book](https://www.deeplearningbook.org/) by Goodfellow, Bengio, and Courville  

A list of key papers in deep learning will also be provided.

---
## Grading
- **Quizzes:** 25%  
- **Programming Assignments:** 35%  
- **Midterm:** 20%  
- **Final Project:** 20% (Proposal: 8%, Final Report: 12%)  

Only the best **5** out of 10 quizzes and assignments will count toward the final grade.

---
## Schedule

- **Week 1: Introduction to Neural Networks**. [Slides](/assets/pdf/teaching/csc578/01_intro.pdf), [Video](https://courseonline.cdm.depaul.edu/courseplayer/courses/64511/lecture/485761) 
  - [Deep Learning](https://www.nature.com/articles/nature14539), *Nature 2015*  

- **Week 2: Training Neural Networks**. [Slides](/assets/pdf/teaching/csc578/02_train.pdf), [Video](#)  
  - [Learning Representations by Back-propagating Errors](https://www.nature.com/articles/323533a0), *Nature 1986*  
  - [Understanding the Difficulty of Training DNNs](https://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf), *AISTAT 2010*  
  - [On the Difficulty of Training RNN](https://proceedings.mlr.press/v28/pascanu13.html), *ICML 2013*  

- **Week 3: Advanced Optimizers**. [Slides](/assets/pdf/teaching/csc578/03_opt.pdf), [Video](#)  
  - [On the Importance of Initialization and Momentum in DL](https://proceedings.mlr.press/v28/sutskever13.html), *ICML 2013*  
  <!-- - [Adaptive Subgradient Methods for Online Learning and Stochastic Optimization](https://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf), *JMLR 2011* -->
  - [Adam: A method for stochastic optimization](https://arxiv.org/abs/1412.6980), *ICLR 2017*
  - [RMSProp: Divide the Gradient by a Running Average of Its Recent Magnitude](https://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf), *Lecture by Geoff Hinton, 2012*  

- **Week 4: Generalization and Regularization**. [Slides](/assets/pdf/teaching/csc578/04_Gen.pdf), [Video](#)  
  - [Understanding Deep Learning Requires Rethinking Generalization](https://arxiv.org/abs/1611.03530), *ICLR 2017*  

- **Week 5: CNNs**. [Slides](/assets/pdf/teaching/csc578/05_cnn.pdf), [Video](#)  
  - [ImageNet Classification with Deep Convolutional Neural Networks](https://dl.acm.org/doi/10.1145/3065386), *NeurIPS 2012*  

- **Week 6: Learning with CNNs**. [Slides](/assets/pdf/teaching/csc578/06_cv.pdf), [Video](#)  
  - [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167), *ICML 2015*  

- **Week 7: RNNs**. [Slides](/assets/pdf/teaching/csc578/07_rnn.pdf), [Video](#)  
  - [Learning to Forget: Continual Prediction with LSTM](https://www.sciencedirect.com/science/article/abs/pii/S0893608005001206), *Neural Computation 2005*  

- **Week 8: Seq2Seq Models**. [Slides](/assets/pdf/teaching/csc578/08_seq2seq.pdf), [Video](#)  
  - [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215), *NeurIPS 2014*  

- **Week 9: Transformers and LLMs**. [Slides](/assets/pdf/teaching/csc578/09_llm.pdf), [Video](#)  
  - [Attention Is All You Need](https://arxiv.org/abs/1706.03762), *NeurIPS 2017*  

- **Week 10: GNNs**. [Slides](/assets/pdf/teaching/csc578/10_gnn.pdf), [Video](#)  
  - [Semi-Supervised Classification with Graph Convolutional Networks](https://arxiv.org/abs/1609.02907), *ICLR 2017*  

---
## Additional Reading
- [Review of Linear Algebra](/assets/pdf/teaching/cs229-linalg.pdf) by Zico Kolter and Chuong Do from Stanford
- [Review of Probability Theory](/assets/pdf/teaching/cs229-prob.pdf) by Arian Maleki and Tom Do from Stanford 

---
## Assignments
- **Assignment 1: Python Basics and Multilayer Perceptron**  
  [Download Notebook](/assets/jupyter/assignment1.ipynb) | [Open in Colab](https://colab.research.google.com/github/gaotx-cs/gaotx-cs.github.io/blob/main/assets/jupyter/assignment1.ipynb)

