<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Neural Networks and Deep Learning | Tianxiang Gao </title> <meta name="author" content="Tianxiang Gao"> <meta name="description" content="This course covers the foundations of deep learning, including fundamental neural network architectures (e.g., multilayer perceptrons) and training methodologies, including advanced optimization techniques (e.g., momentum, RMSprop, Adam). It also addresses generalization and regularization strategies (e.g., overparameterization, the double descent phenomenon, and weight decay). We will explore cutting-edge neural network architectures, including convolutional neural networks (CNNs), recurrent neural networks (RNNs), transformers (e.g., GPT and BERT), and graph neural networks (GNNs). Students will gain hands-on experience by implementing these models and applying them to real-world problems in computer vision, natural language processing, and graph machine learning. "> <meta name="keywords" content="deep learning, graph representation, generative AI"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/infinity.png?cce2813cc4e4c68081a788748b6a0a2e"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://gaotx-cs.github.io/teaching/csc578/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Tianxiang</span> Gao </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/news/">News </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/teaching/">Teaching <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/team/">Team </a> </li> <li class="nav-item "> <a class="nav-link" href="/aispresso/">AiSpresso </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="container mt-5"> <h1 class="font-weight-bold">CSC578: Neural Networks and Deep Learning</h1> <hr> <h2 id="Personnel">Personnel</h2> <ul> <li> <strong>Instructor:</strong> <a href="https://gaotx-cs.github.io/" target="_blank">Tianxiang Gao</a> </li> <li> <strong>Meeting time:</strong> Thursdays 5:45PM - 9:00PM</li> <li> <strong>Location:</strong> CDM Center 224 at Loop Campus </li> <li> <strong>Office Hours:</strong> Mondays 9:00AM-11:00AM | <a href="https://depaul.zoom.us/my/gaotx" target="_blank" rel="external nofollow noopener">Zoom</a> </li> <li> <strong>Overview:</strong> <a href="/assets/pdf/teaching/csc578/csc578_syallubs.pdf" target="_blank">Syllabus</a> | <a href="/assets/pdf/teaching/csc578/00_logistics.pdf" target="_blank">Slides</a> </li> <li> <strong>Discussion:</strong> <a href="https://discord.gg/JxVhZw8ZWB" target="_blank" rel="external nofollow noopener">Discord</a> </li> </ul> <hr> <h2>Course Description</h2> <p>This course covers the foundations of deep learning, including fundamental neural network architectures (e.g., multilayer perceptrons) and training methodologies, including advanced optimization techniques (e.g., momentum, RMSprop, Adam). It also addresses generalization and regularization strategies (e.g., overparameterization, the double descent phenomenon, and weight decay). We will explore cutting-edge neural network architectures, including convolutional neural networks (CNNs), recurrent neural networks (RNNs), transformers (e.g., GPT and BERT), and graph neural networks (GNNs). Students will gain hands-on experience by implementing these models and applying them to real-world problems in computer vision, natural language processing, and graph machine learning. </p> <hr> <p class="mt-4"></p> <h2 id="prerequisites">Prerequisites</h2> <ul> <li> <a href="https://www.cdm.depaul.edu/academics/pages/courseinfo.aspx?Subject=CSC&amp;CatalogNbr=412" rel="external nofollow noopener" target="_blank">CSC 412</a> provides basic knowledge in linear algebra, multivariate calculus, and probability.</li> <li> <a href="https://www.cdm.depaul.edu/academics/pages/courseinfo.aspx?CrseId=012551" rel="external nofollow noopener" target="_blank">DSC 478</a> or <a href="https://www.cdm.depaul.edu/academics/pages/courseinfo.aspx?CrseId=001513" rel="external nofollow noopener" target="_blank">CSC 480</a> introduces the fundamental concepts of artificial intelligence and machine learning.</li> <li>You will implement and train deep neural networks using PyTorch, so basic Python proficiency is required.</li> </ul> <hr> <h2 id="textbook">Textbook</h2> <p>No textbook is required. Materials will be drawn from classical books and recent papers. Recommended readings:</p> <ul> <li> <a href="http://neuralnetworksanddeeplearning.com/" rel="external nofollow noopener" target="_blank">Neural Networks and Deep Learning</a> by Michael Nielsen</li> <li> <a href="https://www.deeplearningbook.org/" rel="external nofollow noopener" target="_blank">Deep Learning book</a> by Goodfellow, Bengio, and Courville</li> </ul> <p>A list of key papers in deep learning will also be provided.</p> <hr> <h2 id="grading">Grading</h2> <ul> <li> <strong>Quizzes:</strong> 25%</li> <li> <strong>Programming Assignments:</strong> 35%</li> <li> <strong>Midterm:</strong> 20%</li> <li> <strong>Final Project:</strong> 20% (Proposal: 8%, Final Report: 12%)</li> </ul> <p>Only the best <strong>5</strong> out of 10 quizzes and assignments will count toward the final grade.</p> <hr> <h2 id="schedule">Schedule</h2> <ul> <li> <strong>Week 1: Introduction to Neural Networks</strong>. <a href="/assets/pdf/teaching/csc578/01_intro.pdf">Slides</a>, <a href="https://courseonline.cdm.depaul.edu/courseplayer/courses/64511/lecture/485761" rel="external nofollow noopener" target="_blank">Video</a> <ul> <li> <a href="https://www.nature.com/articles/nature14539" rel="external nofollow noopener" target="_blank">Deep Learning</a>, <em>Nature 2015</em> </li> </ul> </li> <li> <strong>Week 2: Training Neural Networks</strong>. <a href="/assets/pdf/teaching/csc578/02_train.pdf">Slides</a>, <a href="https://courseonline.cdm.depaul.edu/courseplayer/courses/64511/lecture/485762" rel="external nofollow noopener" target="_blank">Video</a> <ul> <li> <a href="https://www.nature.com/articles/323533a0" rel="external nofollow noopener" target="_blank">Back-propagation</a>, <em>Nature 1986</em> </li> <li> <a href="https://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf" rel="external nofollow noopener" target="_blank">Understanding the difficulty of training DNNs</a>, <em>AISTAT 2010</em> </li> <li> <a href="https://proceedings.mlr.press/v28/pascanu13.html" rel="external nofollow noopener" target="_blank">On the difficulty of training RNNs</a>, <em>ICML 2013</em> </li> <li> <a href="https://proceedings.mlr.press/v28/pascanu13.html" rel="external nofollow noopener" target="_blank">He initialization</a>, <em>ICCV 2015</em> </li> </ul> </li> <li> <strong>Week 3: Advanced Optimizers</strong>. <a href="/assets/pdf/teaching/csc578/03_opt.pdf">Slides</a>, <a href="https://courseonline.cdm.depaul.edu/courseplayer/courses/64511/lecture/485763" rel="external nofollow noopener" target="_blank">Video</a> <ul> <li> <a href="https://proceedings.mlr.press/v28/sutskever13.html" rel="external nofollow noopener" target="_blank">On the Importance of Initialization and Momentum in Deep Learning</a>, <em>ICML 2013</em> </li> <li> <a href="https://arxiv.org/abs/1412.6980" rel="external nofollow noopener" target="_blank">Adam: A Method for Stochastic Optimization</a>, <em>ICLR 2017</em> </li> <li> <a href="https://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf" rel="external nofollow noopener" target="_blank">RMSProp: Divide the Gradient by a Running Average of Its Recent Magnitude</a>, <em>Lecture Slice by Geoff Hinton, 2012</em> </li> <li> <a href="https://www.stat.cmu.edu/~ryantibs/convexopt/lectures/stochastic-gd.pdf" rel="external nofollow noopener" target="_blank">Stochastic Gradient Descent</a>, <em>Lecture Slice by Ryan Tibshirani at CMU, Fall 2019</em> </li> </ul> </li> <li> <strong>Week 4: Generalization and Regularization</strong>. <a href="/assets/pdf/teaching/csc578/04_Gen.pdf">Slides</a>, <a href="#">Video</a> <ul> <li> <a href="https://arxiv.org/abs/1611.03530" rel="external nofollow noopener" target="_blank">Understanding Deep Learning Requires Rethinking Generalization</a>, <em>ICLR 2017</em> </li> <li> <a href="https://jmlr.org/papers/v15/srivastava14a.html" rel="external nofollow noopener" target="_blank">Dropout: A Simple Way to Prevent Neural Networks from Overfitting</a>, <em>JMLR 2015</em> </li> <li> <a href="https://arxiv.org/abs/1803.05407" rel="external nofollow noopener" target="_blank">Averaging Weights Leads to Wider Optima and Better Generalization</a>, <em>UAI 2018</em> </li> <li> <a href="https://arxiv.org/abs/1609.04836" rel="external nofollow noopener" target="_blank">On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima</a>, <em>ICLR 2017</em> </li> <li> <a href="https://openreview.net/forum?id=Skq89Scxx" rel="external nofollow noopener" target="_blank">SGDR: Stochastic Gradient Descent with Warm Restarts</a>, <em>ICLR 2017</em> </li> <li> <a href="https://arxiv.org/abs/1812.11118" rel="external nofollow noopener" target="_blank">Reconciling modern machine learning practice and the bias-variance trade-off</a>, <em>PNAS 2019</em> </li> </ul> </li> <li> <strong>Week 5: CNNs</strong>. <a href="/assets/pdf/teaching/csc578/05_cnn.pdf">Slides</a>, <a href="#">Video</a> <ul> <li> <a href="https://dl.acm.org/doi/10.1145/3065386" rel="external nofollow noopener" target="_blank">ImageNet Classification with Deep Convolutional Neural Networks</a>, <em>NeurIPS 2012</em> </li> <li> <a href="https://arxiv.org/abs/1505.04597" rel="external nofollow noopener" target="_blank">U-Net: Convolutional Networks for Biomedical Image Segmentation</a>, <em>MICCAI 2015</em> </li> <li> <a href="https://dl.acm.org/doi/abs/10.1145/1553374.1553453" rel="external nofollow noopener" target="_blank">Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations</a>, <em>ICML 2009</em> </li> <li> <a href="https://arxiv.org/abs/1409.1556" rel="external nofollow noopener" target="_blank">Very deep convolutional networks for large-scale image recognition</a>, <em>ICLR 2015</em> </li> <li> <a href="https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf" rel="external nofollow noopener" target="_blank">Deep residual learning for image recognition</a>, <em>CVPR 2016</em> </li> <li> <a href="https://arxiv.org/abs/1502.03167" rel="external nofollow noopener" target="_blank">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a>, <em>ICML 2015</em> </li> </ul> </li> <li> <strong>Week 6: Learning with CNNs</strong>. <a href="/assets/pdf/teaching/csc578/06_cv.pdf">Slides</a>, <a href="#">Video</a> <ul> <li> <a href="https://arxiv.org/abs/1312.4400" rel="external nofollow noopener" target="_blank">Network in Network</a>, <em>ICLR 2014</em> </li> <li> <a href="https://arxiv.org/abs/1409.4842" rel="external nofollow noopener" target="_blank">Going Deeper with Convolutions</a>, <em>CVPR 2014</em> </li> <li> <a href="https://arxiv.org/abs/1801.04381v4" rel="external nofollow noopener" target="_blank">MobileNetV2: Inverted Residuals and Linear Bottlenecks</a>, <em>CVPR 2018</em> </li> <li> <a href="https://arxiv.org/abs/1905.11946" rel="external nofollow noopener" target="_blank">EfficientNet: Rethinking Model Scaling for CNNs</a>, <em>ICML 2019</em> </li> <li> <a href="https://arxiv.org/abs/1502.03167" rel="external nofollow noopener" target="_blank">You Only Look Once: Unified, Real-Time Object Detection</a>, <em>CVPR 2016</em> </li> <li> <a href="https://ieeexplore.ieee.org/document/6909616" rel="external nofollow noopener" target="_blank">DeepFace: Closing the Gap to Human-Level Performance in Face Verification</a>, <em>CVPR 2014</em> </li> <li> <a href="https://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Schroff_FaceNet_A_Unified_2015_CVPR_paper.html" rel="external nofollow noopener" target="_blank">FaceNet: A Unified Embedding for Face Recognition and Clustering</a>, <em>CVPR 2015</em> </li> <li> <a href="https://arxiv.org/abs/1311.2901" rel="external nofollow noopener" target="_blank">Visualizing and Understanding Convolutional Networks</a>, <em>ECCV 2014</em> </li> </ul> </li> <li> <strong>Week 7: RNNs</strong>. <a href="/assets/pdf/teaching/csc578/07_rnn.pdf">Slides</a>, <a href="#">Video</a> <ul> <li> <a href="https://www.sciencedirect.com/science/article/abs/pii/S0893608005001206" rel="external nofollow noopener" target="_blank">Learning to Forget: Continual Prediction with LSTM</a>, <em>Neural Computation 2005</em> </li> <li> <a href="https://arxiv.org/pdf/1406.1078" rel="external nofollow noopener" target="_blank">Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation</a>, <em>EMNL 2014</em> </li> <li> <a href="https://ieeexplore.ieee.org/abstract/document/650093" rel="external nofollow noopener" target="_blank">Bidirectional Recurrent Neural Networks</a>, <em>IEEE TSP 1997</em> </li> <li> <a href="https://aclanthology.org/N13-1090.pdf" rel="external nofollow noopener" target="_blank">Linguistic Regularities in Continuous Space Word Representations</a>, <em>NAACL 2013</em> </li> <li> <a href="https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf" rel="external nofollow noopener" target="_blank">A Neural Probabilistic Language Model</a>, <em>JMLR 2003</em> </li> <li> <a href="https://arxiv.org/pdf/1301.3781" rel="external nofollow noopener" target="_blank">Efficient Estimation of Word Representations in Vector Space</a>, <em>ICLR 2013</em> </li> <li> <a href="https://aclanthology.org/D14-1162.pdf" rel="external nofollow noopener" target="_blank">GloVe: Global Vectors for Word Representation</a>, <em>EMNLP 2014</em> </li> </ul> </li> <li> <strong>Week 8: Seq2Seq Models and Transformers</strong>. <a href="/assets/pdf/teaching/csc578/08_seq2seq.pdf">Slides</a>, <a href="#">Video</a> <ul> <li> <a href="https://arxiv.org/pdf/1406.1078" rel="external nofollow noopener" target="_blank">Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation</a>, <em>EMNLP 2014</em> </li> <li> <a href="https://arxiv.org/abs/1409.3215" rel="external nofollow noopener" target="_blank">Sequence to Sequence Learning with Neural Networks</a>, <em>NeurIPS 2014</em> </li> <li> <a href="https://proceedings.neurips.cc/paper_files/paper/2016/file/a486cd07e4ac3d270571622f4f316ec5-Paper.pdf" rel="external nofollow noopener" target="_blank">BLEU: a Method for Automatic Evaluation of Machine Translation</a>, <em>ACL 2002</em> </li> <li> <a href="https://papers.baulab.info/papers/Bahdanau-2015.pdf" rel="external nofollow noopener" target="_blank">Neural Machine Translation by Jointly Learning to Align and Translate</a>, <em>ICLR 2015</em> </li> <li> <a href="https://arxiv.org/abs/1706.03762" rel="external nofollow noopener" target="_blank">Attention Is All You Need</a>, <em>NeurIPS 2017</em> </li> </ul> </li> <li> <strong>Week 9: LLMs and Efficient Transformers</strong>. <a href="/assets/pdf/teaching/csc578/09_llm.pdf">Slides</a>, <a href="#">Video</a> <ul> <li> <a href="https://arxiv.org/abs/1810.04805" rel="external nofollow noopener" target="_blank">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a>, <em>NAACL 2019</em> </li> <li> <a href="https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf" rel="external nofollow noopener" target="_blank">Language Models are Few-Shot Learners</a>, <em>NeurIPS 2020 (Introduced GPT-3)</em> </li> <li> <a href="https://openai.com/index/scaling-laws-for-neural-language-models/" rel="external nofollow noopener" target="_blank">Scaling Laws for Neural Language Models</a>, <em>OpenAI Blog 2020</em> </li> <li> <a href="https://arxiv.org/abs/2203.02155" rel="external nofollow noopener" target="_blank">Training Language Models to Follow Instructions with Human Feedback</a>, <em>NeurIPS 2022</em> </li> </ul> </li> <li> <strong>Week 10: GNNs</strong>. <a href="/assets/pdf/teaching/csc578/10_gnn.pdf">Slides</a>, <a href="#">Video</a> <ul> <li> <a href="https://arxiv.org/abs/1609.02907" rel="external nofollow noopener" target="_blank">Semi-Supervised Classification with Graph Convolutional Networks</a>, <em>ICLR 2017</em> </li> <li> <a href="https://arxiv.org/abs/1704.01212" rel="external nofollow noopener" target="_blank">Neural Message Passing for Quantum Chemistry</a>, <em>ICML 2017</em> </li> <li> <a href="https://arxiv.org/abs/1710.10903" rel="external nofollow noopener" target="_blank">Graph Attention Networks</a>, <em>ICLR 2018</em> </li> <li> <a href="https://arxiv.org/abs/1810.00826" rel="external nofollow noopener" target="_blank">How Powerful are Graph Neural Networks?</a>, <em>ICLR 2019</em> </li> <li> <a href="https://arxiv.org/abs/2205.12454" rel="external nofollow noopener" target="_blank">Recipe for a General, Powerful, Scalable Graph Transformer</a>, <em>NeurIPS 2022</em> </li> </ul> </li> </ul> <hr> <h2 id="additional-reading-and-resources">Additional Reading and Resources</h2> <ul> <li> <a href="/assets/pdf/teaching/cs229-linalg.pdf">Review of Linear Algebra</a>, <em>by Zico Kolter and Chuong Do from Stanford</em> </li> <li> <a href="/assets/pdf/teaching/cs229-prob.pdf">Review of Probability Theory</a>, <em>by Arian Maleki and Tom Do from Stanford</em> </li> <li> <a href="https://www.stat.cmu.edu/~ryantibs/convexopt/" rel="external nofollow noopener" target="_blank">10-725 Convex Optimization Course Notes</a>, <em>by Ryan Tibshirani at CMU, Fall 2019</em> </li> <li> <a href="https://deeplearning.cs.cmu.edu/" rel="external nofollow noopener" target="_blank">11-785 Introduction to Deep Learning</a>, <em>by Bhiksha Raj and Rita Singh at CMU, Fall 2024</em> </li> <li> <a href="">Deep Learning Specialization</a>, <em>by Andrew Ng at Coursera and DeepLearning.AI, Fall 2021</em> </li> <li> <a href="https://cs.nyu.edu/~mohri/mlbook/" rel="external nofollow noopener" target="_blank">Foundations of Machine Learning</a>, <em>Textbook by Mehryar Mohri, 2018</em> </li> <li> <a href="https://link.springer.com/book/10.1007/978-3-319-91578-4" rel="external nofollow noopener" target="_blank">Lectures on Convex Optimization</a>, <em>Textbook by Yurii Nesterov, 2018</em> </li> <li> <a href="https://openreview.net/forum?id=BygfghAcYX" rel="external nofollow noopener" target="_blank">Towards Understanding the Role of Over-Parametrization in Generalization of Neural Networks</a>, <em>ICLR 2019</em> </li> <li> <a href="https://arxiv.org/abs/1603.09382" rel="external nofollow noopener" target="_blank">Deep Networks with Stochastic Depth</a>, <em>ECCV 2016</em> </li> <li> <a href="https://openreview.net/forum?id=B1g5sA4twr" rel="external nofollow noopener" target="_blank">Deep Double Descent: Where Bigger Models and More Data Hurt</a>, <em>ICLR 2020</em> </li> <li> <a href="https://arxiv.org/abs/1303.5778" rel="external nofollow noopener" target="_blank">Speech recognition with deep recurrent neural networks</a>, <em>ICASSP 2013</em> </li> <li> <a href="https://proceedings.neurips.cc/paper_files/paper/2016/file/a486cd07e4ac3d270571622f4f316ec5-Paper.pdf" rel="external nofollow noopener" target="_blank">Man is to computer programmer as woman is to homemaker? Debiasing word embeddings</a>, <em>NeurIPS 2016</em> </li> <li> <a href="https://arxiv.org/abs/1411.4555" rel="external nofollow noopener" target="_blank">Show and Tell: A Neural Image Caption Generator</a>, <em>CVPR 2015</em> </li> <li> <a href="https://openai.com/index/language-unsupervised/" rel="external nofollow noopener" target="_blank">Improving Language Understanding by Generative Pre-Training</a>, <em>OpenAI Blog 2018 (Introduced GPT-1)</em> </li> <li> <a href="https://openai.com/index/better-language-models/" rel="external nofollow noopener" target="_blank">Language Models are Unsupervised Multitask Learners</a>, <em>OpenAI Blog 2019 (Introduced GPT-2)</em> </li> <li> <a href="https://openreview.net/forum?id=yzkSU5zdwD&amp;utm_source=substack&amp;utm_medium=email" rel="external nofollow noopener" target="_blank">Emergent Abilities of Large Language Models</a>, <em>TMLR 2022</em> </li> <li> <a href="https://arxiv.org/abs/2203.15556" rel="external nofollow noopener" target="_blank">Training Compute-Optimal Large Language Models</a>, <em>NeurIPS 2022</em> </li> <li> <a href="https://arxiv.org/abs/1706.03741" rel="external nofollow noopener" target="_blank">Deep Reinforcement Learning from Human Preferences</a>, <em>NeurIPS 2017</em> </li> <li> <a href="https://nlp.seas.harvard.edu/annotated-transformer/" rel="external nofollow noopener" target="_blank">The Annotated Transformer</a>, <em>Harvard NLP Blog 2018</em> </li> <li> <a href="https://arxiv.org/abs/2101.03961" rel="external nofollow noopener" target="_blank">Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity</a>, <em>JMLR 2022</em> </li> <li> <a href="https://arxiv.org/abs/1810.05997" rel="external nofollow noopener" target="_blank">Predict Then Propagate: Graph Neural Networks Meet Personalized PageRank</a>, <em>ICLR 2018</em> </li> </ul> <hr> <h2 id="assignments">Assignments</h2> <ul> <li> <p><strong>Assignment 1: Python Basics and Multilayer Perceptron</strong><br> <a href="/assets/jupyter/csc578/HW01.ipynb">Download Notebook</a> | <a href="https://colab.research.google.com/github/gaotx-cs/gaotx-cs.github.io/blob/main/assets/jupyter/csc578/HW01.ipynb" rel="external nofollow noopener" target="_blank">Open in Colab</a></p> </li> <li> <p><strong>Assignment 2: Neural Network Training: MLP, Backpropogation, Gradient Descent</strong><br> <a href="/assets/jupyter/csc578/HW02.ipynb">Download Notebook</a> | <a href="https://colab.research.google.com/github/gaotx-cs/gaotx-cs.github.io/blob/main/assets/jupyter/csc578/HW02.ipynb" rel="external nofollow noopener" target="_blank">Open in Colab</a></p> </li> <li> <p><strong>Assignment 3: Advanced Optimizers: Accelerated GD, RMSProp, Adam</strong><br> <a href="/assets/jupyter/csc578/HW03.ipynb">Download Notebook</a> | <a href="https://colab.research.google.com/github/gaotx-cs/gaotx-cs.github.io/blob/main/assets/jupyter/csc578/HW03.ipynb" rel="external nofollow noopener" target="_blank">Open in Colab</a></p> </li> <li> <p><strong>Assignment 4: Generalization and Regularization: PyTorch, Autograd, Hyperparameter Tune, Overparameterization</strong><br> <a href="/assets/jupyter/csc578/HW04.ipynb">Download Notebook</a> | <a href="https://colab.research.google.com/github/gaotx-cs/gaotx-cs.github.io/blob/main/assets/jupyter/csc578/HW04.ipynb" rel="external nofollow noopener" target="_blank">Open in Colab</a></p> </li> <li> <p><strong>Assignment 5: Introduction to CNNs: Implementation of CNNs, Semantic Segmentation through UNet</strong><br> <a href="/assets/jupyter/csc578/HW05.ipynb">Download Notebook</a> | <a href="https://colab.research.google.com/github/gaotx-cs/gaotx-cs.github.io/blob/main/assets/jupyter/csc578/HW05.ipynb" rel="external nofollow noopener" target="_blank">Open in Colab</a></p> </li> <li> <p><strong>Assignment 6: Computer Vision with CNNs: Neural Style Transfer using Pre-Trained VGG</strong><br> <a href="/assets/jupyter/csc578/HW06.ipynb">Download Notebook</a> | <a href="https://colab.research.google.com/github/gaotx-cs/gaotx-cs.github.io/blob/main/assets/jupyter/csc578/HW06.ipynb" rel="external nofollow noopener" target="_blank">Open in Colab</a></p> </li> <li> <p><strong>Assignment 7: Recurrent Neural Networks: Implementation and Training</strong><br> <a href="/assets/jupyter/csc578/HW07.ipynb">Download Notebook</a> | <a href="https://colab.research.google.com/github/gaotx-cs/gaotx-cs.github.io/blob/main/assets/jupyter/csc578/HW07.ipynb" rel="external nofollow noopener" target="_blank">Open in Colab</a></p> </li> <li> <p><strong>Assignment 8: Seq2seq: Neural Machine Translation</strong><br> <a href="/assets/jupyter/csc578/HW08.ipynb">Download Notebook</a> | <a href="https://colab.research.google.com/github/gaotx-cs/gaotx-cs.github.io/blob/main/assets/jupyter/csc578/HW08.ipynb" rel="external nofollow noopener" target="_blank">Open in Colab</a></p> </li> <li> <p><strong>Assignment 9: Transformer: GPT and ChatBot</strong><br> <a href="/assets/jupyter/csc578/HW09.ipynb">Download Notebook</a> | <a href="https://colab.research.google.com/github/gaotx-cs/gaotx-cs.github.io/blob/main/assets/jupyter/csc578/HW09.ipynb" rel="external nofollow noopener" target="_blank">Open in Colab</a></p> </li> </ul> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Tianxiang Gao. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?70d799092f862ad98c7876aa47712e20"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> </body> </html>