<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Tianxiang Gao </title> <meta name="author" content="Tianxiang Gao"> <meta name="description" content=""> <meta name="keywords" content="deep learning, graph representation, generative AI"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/infinity.png?cce2813cc4e4c68081a788748b6a0a2e"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://gaotx-cs.github.io/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <div class="navbar-brand social"> <a href="https://discord.com/users/1291806465195114601" title="Discord" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-discord"></i></a> <a href="mailto:%74.%67%61%6F@%64%65%70%61%75%6C.%65%64%75" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://github.com/gaotx-cs" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/gaotx" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://scholar.google.com/citations?user=iNLlIbQAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> </div> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/news/">News </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">Teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/team/">Team </a> </li> <li class="nav-item "> <a class="nav-link" href="/aispresso/">AiSpresso </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Tianxiang</span> Gao </h1> <p class="desc">Assistant Professor @ DePaul</p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/adam_prof_pic-480.webp 480w,/assets/img/adam_prof_pic-800.webp 800w,/assets/img/adam_prof_pic-1400.webp 1400w," type="image/webp" sizes="(min-width: 1000px) 291.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img/adam_prof_pic.jpg?5248aefec7a89b334c6ca207a6f9454c" class="img-fluid z-depth-1 rounded-circle" width="100%" height="auto" alt="adam_prof_pic.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"> <p>Jarvis College of CDM 712</p> <p>243 South Wabash Avenue</p> <p>Chicago, IL 60604</p> </div> </div> <div class="clearfix"> <p>Welcome! Iâ€™m Tianxiang (å¤©ç¿”), but feel free to call me Adamâ€”Iâ€™m happy with either! Since July 2024, Iâ€™ve been an Assistant Professor in the <a href="https://www.cdm.depaul.edu/academics/Pages/School-of-Computing.aspx" rel="external nofollow noopener" target="_blank">School of Computing</a> at <a href="https://www.depaul.edu/Pages/default.aspx" rel="external nofollow noopener" target="_blank">DePaul University</a>.</p> <p>ğŸ“Before joining DePaul, I earned my Ph.D. in Computer Science with a co-major in Applied Mathematics from <a href="https://www.iastate.edu/" rel="external nofollow noopener" target="_blank">Iowa State University</a>, where I was co-advised by <a href="https://faculty.sites.iastate.edu/hygao/" rel="external nofollow noopener" target="_blank">Dr. Hongyang Gao</a>, <a href="https://faculty.sites.iastate.edu/hliu/" rel="external nofollow noopener" target="_blank">Dr. Hailiang Liu</a>, and <a href="https://kevinliu-osu.github.io/" rel="external nofollow noopener" target="_blank">Dr. Jia (Kevin) Liu</a>. My academic journey began with a bachelorâ€™s degree in Mechanical Engineering from <a href="https://www.ytu.edu.cn/" rel="external nofollow noopener" target="_blank">Yantai University</a>.</p> <h2 id="research">Research</h2> <p>ğŸ’¡My research focuses on <strong>deep learning theory</strong>, <strong>generative AI</strong>, and <strong>graph representation learning</strong>. I enjoy exploring fundamental problems that mysteriously arise from real-world applications and offering insightful guidelines to advance practice.</p> <p>ğŸŒŸ<span style="color: red; font-weight: bold;">Immediate Openings!</span></p> <ul> <li>I am recruiting Ph.D. students starting in Fall 2025 and Winter 2026.</li> <li>I am looking for multiple Research Assistants (RAs) for Spring 2025 and Summer 2025 to work on projects in deep learning theory and graph representation learning.</li> </ul> <p>If you are interested, please send your CV, transcripts, publications (if available), and GRE/TOEFL scores (if available) to <a href="mailto:t.gao@depaul.edu">tgao9@depaul.edu</a>.</p> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Mar 20, 2025</th> <td> ğŸ‰ Exciting news: Our new course, <span style="color: royalblue; font-weight: bold;">CSC 594: Deep Generative Models</span> at DePaul University, is supported by <span style="color: royalblue; font-weight: bold;">Google Cloud Education</span> Credits! Grateful for Google Cloudâ€™s support! ğŸš€ </td> </tr> <tr> <th scope="row" style="width: 20%">Jan 22, 2025</th> <td> ğŸ“¢ Our paper, <a href="https://openreview.net/forum?id=AoraWUmpLU" rel="external nofollow noopener" target="_blank">Exploring the Impact of Activation Functions in Training Neural ODEs</a>, has been accepted to <span style="color: royalblue; font-weight: bold;">ICLR2025</span> as an <span style="color: red; font-weight: bold;">oral presentation (1.8% acceptance rate)</span>! <br> ğŸ” Key Highlights: <ul> <li>We establish the global convergence of neural ODEs by analyzing their training dynamics.</li> <li>Smoothness &amp; nonlinearity of activation functions are the secret sauceâ€”not only ensuring convergence but also accelerating training.</li> <li>Surprisingly, for large-scale neural ODEs, fixed-step solvers can be more efficient than adaptive solvers!</li> </ul> Looking forward to presenting and discussing these insights in Singapore! ğŸš€ </td> </tr> <tr> <th scope="row" style="width: 20%">Dec 21, 2024</th> <td> ğŸ‰ Excited to share that all my masterâ€™s studentsâ€”<span style="color: royalblue; font-weight: bold;">Nishant Singh</span>, <span style="color: royalblue; font-weight: bold;">Jagriti Suneja</span>, and <span style="color: royalblue; font-weight: bold;">Mohammed Azeezulla</span>â€”have each received prestigious <a href="https://www.cdm.depaul.edu/academics/research/Pages/GRAP.aspx" rel="external nofollow noopener" target="_blank">Graduate Research Assistant Program (GRAP) Award</a> from <span style="color: royalblue; font-weight: bold;">DePaul CDM</span>! Congratulations to all of them for their hard work and dedication! </td> </tr> <tr> <th scope="row" style="width: 20%">Oct 18, 2024</th> <td> ğŸ’¡ Excited to share that I gave a talk on <span style="color: green; font-weight: bold;">â€œBuilding Your Own Customized GPT Teaching Assistant for â€˜Freeâ€™â€</span> at the <a href="https://blogs.depaul.edu/ai-institute/ai-in-teaching/" rel="external nofollow noopener" target="_blank">AI in Teaching Symposium</a> held by <a href="https://blogs.depaul.edu/ai-institute/welcome-to-the-depaul-ai-institute/" rel="external nofollow noopener" target="_blank">DePaul AI Institute</a>! ğŸ“šâœ¨ You can check out the recording <a href="https://blogs.depaul.edu/ai-institute/adam-gao-building-your-own-customized-gpt-teaching-assistant-for-free/" rel="external nofollow noopener" target="_blank">here</a>.ğŸ“º </td> </tr> <tr> <th scope="row" style="width: 20%">Oct 10, 2024</th> <td> ğŸ“¢ Iâ€™m happy to be invited at the <a href="https://csh.depaul.edu/academics/mathematical-sciences/research/Pages/seminars.aspx" rel="external nofollow noopener" target="_blank">Math Colloquium</a> hosted by the <a href="https://csh.depaul.edu/academics/mathematical-sciences/Pages/default.aspx" rel="external nofollow noopener" target="_blank">Department of Mathematical Sciences</a> at <a href="https://www.depaul.edu/Pages/default.aspx" rel="external nofollow noopener" target="_blank">DePaul University</a>. <ul> <li>ğŸ—“ï¸ Date: Friday, November 1, 2024</li> <li>â° Time: 2:00 PM â€“ 3:00 PM</li> <li>ğŸ“ Location: Arts &amp; Letters Hall, Room 207</li> <li>ğŸ™ï¸ Topic: <span style="color: royalblue; font-weight: bold;">â€œLearnability in Infinite-Depth Neural Networks: Overparameterization and the Role of Gaussian Processesâ€</span> </li> </ul> </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICLR 2025</abbr> </div> <div id="gao2025exp" class="col-sm-8"> <div class="title">Global Convergence in Neural ODEs: Impact of Activation Functions</div> <div class="author"> <em>Tianxiang Gao</em>,Â Siyuan Sun,Â Hailiang Liu, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Hongyang Gao' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In the 13th International Conference on Learning Representations (ICLR)</em>, 2025 </div> <div class="periodical" style="font-weight: bold; color: red;"> Oral Presentation (1.8% Acceptance Rate) </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://openreview.net/forum?id=AoraWUmpLU" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Neural Ordinary Differential Equations (ODEs) have been successful in various applications due to their continuous nature and parameter-sharing efficiency. However, these unique characteristics also introduce challenges in training, particularly with respect to gradient computation accuracy and convergence analysis. In this paper, we address these challenges by investigating the impact of activation functions. We demonstrate that the properties of activation functionsâ€”specifically smoothness and nonlinearityâ€”are critical to the training dynamics. Smooth activation functions guarantee globally unique solutions for both forward and backward ODEs, while sufficient nonlinearity is essential for maintaining the spectral properties of the Neural Tangent Kernel (NTK) during training. Together, these properties enable us to establish the global convergence of Neural ODEs under gradient descent in overparameterized regimes. Our theoretical findings are validated by numerical experiments, which not only support our analysis but also provide practical guidelines for scaling Neural ODEs, potentially leading to faster training and improved performance in real-world applications.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">NeurIPS 2023</abbr> </div> <div id="gao2023wide" class="col-sm-8"> <div class="title">Wide neural networks as gaussian processes: Lessons from deep equilibrium models</div> <div class="author"> <em>Tianxiang Gao</em>,Â Xiaokai Huo,Â Hailiang Liu, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Hongyang Gao' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In the 36th Advances in Neural Information Processing Systems (NeruIPS)</em>, 2023 </div> <div class="periodical" style="font-weight: bold; color: red;"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://proceedings.neurips.cc/paper_files/paper/2023/hash/ac24656b0b5f543b202f748d62041637-Abstract-Conference.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Neural networks with wide layers have attracted significant attention due to their equivalence to Gaussian processes, enabling perfect fitting of training data while maintaining generalization performance, known as benign overfitting. However, existing results mainly focus on shallow or finite-depth networks, necessitating a comprehensive analysis of wide neural networks with infinite-depth layers, such as neural ordinary differential equations (ODEs) and deep equilibrium models (DEQs). In this paper, we specifically investigate the deep equilibrium model (DEQ), an infinite-depth neural network with shared weight matrices across layers. Our analysis reveals that as the width of DEQ layers approaches infinity, it converges to a Gaussian process, establishing what is known as the Neural Network and Gaussian Process (NNGP) correspondence. Remarkably, this convergence holds even when the limits of depth and width are interchanged, which is not observed in typical infinite-depth Multilayer Perceptron (MLP) networks. Furthermore, we demonstrate that the associated Gaussian vector remains non-degenerate for any pairwise distinct input data, ensuring a strictly positive smallest eigenvalue of the corresponding kernel matrix using the NNGP kernel. These findings serve as fundamental elements for studying the training and generalization of DEQs, laying the groundwork for future research in this area.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICLR 2022</abbr> </div> <div id="gao2022a" class="col-sm-8"> <div class="title">A global convergence theory for deep implicit networks via over-parameterization</div> <div class="author"> <em>Tianxiang Gao</em>,Â Hailiang Liu,Â Jia Liu, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Hridesh Rajan, Hongyang Gao' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>In the 10th International Conference on Learning Representations (ICLR)</em>, 2022 </div> <div class="periodical" style="font-weight: bold; color: red;"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://openreview.net/forum?id=R332S76RjxS" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Implicit deep learning has received increasing attention recently, since it generalizes the recursive prediction rules of many commonly used neural network architectures. Its prediction rule is provided implicitly based on the solution of an equilibrium equation. Although many recent studies have experimentally demonstrates its superior performances, the theoretical understanding of implicit neural networks is limited. In general, the equilibrium equation may not be well-posed during the training. As a result, there is no guarantee that a vanilla (stochastic) gradient descent (SGD) training nonlinear implicit neural networks can converge. This paper fills the gap by analyzing the gradient flow of Rectified Linear Unit (ReLU) activated implicit neural networks. For an m-width implicit neural network with ReLU activation and n training samples, we show that a randomly initialized gradient descent converges to a global minimum at a linear rate for the square loss function if the implicit neural network is over-parameterized. It is worth noting that, unlike existing works on the convergence of (S)GD on finitelayer over-parameterized neural networks, our convergence results hold for implicit neural networks, where the number of layers is infinite.</p> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> Â© Copyright 2026 Tianxiang Gao. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?70d799092f862ad98c7876aa47712e20"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> </body> </html>