---
layout: post
date: 2025-01-22 09:00:00-0500
inline: true
related_posts: false
---

📢 Our paper, [Exploring the Impact of Activation Functions in Training Neural ODEs](https://openreview.net/forum?id=AoraWUmpLU), has been accepted to <span style="color: royalblue; font-weight: bold;">ICLR2025</span> as an <span style="color: red; font-weight: bold;">oral presentation (1.8% acceptance rate)</span>! 

<br>
🔍 Key Highlights:

- We establish the global convergence of neural ODEs by analyzing their training dynamics.
- Smoothness & nonlinearity of activation functions are the secret sauce—not only ensuring convergence but also accelerating training.
- Surprisingly, for large-scale neural ODEs, fixed-step solvers can be more efficient than adaptive solvers!

Looking forward to presenting and discussing these insights in Singapore! 🚀