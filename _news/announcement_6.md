---
layout: post
date: 2025-01-22 09:00:00-0500
inline: true
related_posts: false
---

ğŸ“¢ Our paper, [Exploring the Impact of Activation Functions in Training Neural ODEs](https://openreview.net/forum?id=AoraWUmpLU), has been accepted to <span style="color: royalblue; font-weight: bold;">ICLR2025</span> as an <span style="color: red; font-weight: bold;">oral presentation (1.8% acceptance rate)</span>! 

<br>
ğŸ” Key Highlights:

- We establish the global convergence of neural ODEs by analyzing their training dynamics.
- Smoothness & nonlinearity of activation functions are the secret sauceâ€”not only ensuring convergence but also accelerating training.
- Surprisingly, for large-scale neural ODEs, fixed-step solvers can be more efficient than adaptive solvers!

Looking forward to presenting and discussing these insights in Singapore! ğŸš€